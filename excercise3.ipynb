{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#today_main_news  >  div.hdline_news  >  ul  >  li'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = \"#today_main_news > div.hdline_news > ul > li:nth-child(1)\"\n",
    "\n",
    "selector_list = selector.split(\">\")\n",
    "selector_list[-1] = selector_list[-1].split(\":\")[0]\n",
    "\n",
    "\" > \".join(selector_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지난시간 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 x 1 = 2\n",
      "2 x 2 = 4\n",
      "2 x 3 = 6\n",
      "2 x 4 = 8\n",
      "2 x 5 = 10\n",
      "2 x 6 = 12\n",
      "2 x 7 = 14\n",
      "2 x 8 = 16\n",
      "2 x 9 = 18\n"
     ]
    }
   ],
   "source": [
    "def gugu_com(x=2):\n",
    "    [print(f\"{x} x {i} = {x*i}\") for i in range(1, 10)]\n",
    "\n",
    "gugu_com(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5, 6],\n",
       " [2, 4, 6, 8, 10, 12],\n",
       " [3, 6, 9, 12, 15, 18],\n",
       " [4, 8, 12, 16, 20, 24],\n",
       " [5, 10, 15, 20, 25, 30],\n",
       " [6, 12, 18, 24, 30, 36]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "die = [i for i in range(1,7)]\n",
    "\n",
    "[[j*i for i in die] for j in die]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4, 5, 6, 7],\n",
       " [3, 4, 5, 6, 7, 8],\n",
       " [4, 5, 6, 7, 8, 9],\n",
       " [5, 6, 7, 8, 9, 10],\n",
       " [6, 7, 8, 9, 10, 11],\n",
       " [7, 8, 9, 10, 11, 12]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "die = [i for i in range(1,7)]\n",
    "\n",
    "dice_sum = [[j+i for i in die] for j in die]\n",
    "dice_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "text = \"\"\"Python is a very simple programming language so even if you are new to programming, you can learn python without facing any issues.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = Counter(text.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'python': 2,\n",
       "         'is': 1,\n",
       "         'a': 1,\n",
       "         'very': 1,\n",
       "         'simple': 1,\n",
       "         'programming': 1,\n",
       "         'language': 1,\n",
       "         'so': 1,\n",
       "         'even': 1,\n",
       "         'if': 1,\n",
       "         'you': 2,\n",
       "         'are': 1,\n",
       "         'new': 1,\n",
       "         'to': 1,\n",
       "         'programming,': 1,\n",
       "         'can': 1,\n",
       "         'learn': 1,\n",
       "         'without': 1,\n",
       "         'facing': 1,\n",
       "         'any': 1,\n",
       "         'issues.': 1})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 개인과제 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVER_PATH = 'C:/Users/Administrator/Desktop/비즈니스_애널리틱스/개인과제/3주차_개인과제/chromedriver.exe' \n",
    "\n",
    "# 끝에 chromedriver.exe를 붙이는 것 잊지 말아야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dynamite\\n방탄소년단'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chrome driver 설정\n",
    "driver = webdriver.Chrome(DRIVER_PATH) \n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "url = \"https://www.melon.com/chart/index.htm\"\n",
    "\n",
    "driver.get(url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# title crawling\n",
    "title = WebDriverWait(driver, 20) \\\n",
    "    .until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#frm > div > table > tbody > tr:nth-child(1) > td:nth-child(4) > div > div\")))\n",
    "\n",
    "# print(\"Title: {}\".format(title.text))\n",
    "\n",
    "title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'취기를 빌려 (취향저격 그녀 X 산들)\\n산들'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2번째 제목 크롤링\n",
    "WebDriverWait(driver, 20) \\\n",
    "    .until(EC.presence_of_element_located((By.XPATH, \"//*[@id='frm']/div/table/tbody/tr[2]/td[4]/div/div\"))).text\n",
    "\n",
    "# 위의 코드와 아래의 코드가 By.XPATH 와 By.CSS_SELECTOR중 어느 것이 쓰이는 지에 따라 어느 정도의 차이가 있는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dynamite\\n방탄소년단', '취기를 빌려 (취향저격 그녀 X 산들)\\n산들', '눈누난나 (NUNU NANA)\\n제시 (Jessi)', '마리아 (Maria)\\n화사 (Hwa Sa)', '다시 여기 바닷가\\n싹쓰리 (유두래곤, 린다G, 비룡)', 'When We Disco (Duet with 선미)\\n박진영', '오래된 노래\\n스탠딩 에그', 'How You Like That\\nBLACKPINK', '에잇(Prod.&Feat. SUGA of BTS)\\n아이유', '내 마음이 움찔했던 순간 (취향저격 그녀 X 규현)\\n규현 (KYUHYUN)', 'Dolphin\\n오마이걸 (OH MY GIRL)', '아로하\\n조정석', 'Downtown Baby\\n블루 (BLOO)', '홀로\\n이하이', '어떻게 지내 (Prod. By VAN.C)\\n오반', 'Summer Hate (Feat. 비)\\n지코 (ZICO)', 'Blueming\\n아이유', '덤디덤디 (DUMDi DUMDi)\\n(여자)아이들', 'Dance Monkey\\nTones And I', 'Memories\\nMaroon 5', 'Not Shy\\nITZY (있지)', '살짝 설렜어 (Nonstop)\\n오마이걸 (OH MY GIRL)', '흔들리는 꽃들 속에서 네 샴푸향이 느껴진거야\\n장범준', 'METEOR\\n창모 (CHANGMO)', '어떻게 이별까지 사랑하겠어, 널 사랑하는 거지\\nAKMU (악동뮤지션)', '작은 것들을 위한 시 (Boy With Luv) (Feat. Halsey)\\n방탄소년단', '사랑은 지날수록 더욱 선명하게 남아\\n전상근', '사랑하게 될 줄 알았어\\n전미도', 'Ice Cream (with Selena Gomez)\\nBLACKPINK', '늦은 밤 너의 집 앞 골목길에서\\n노을', '그 여름을 틀어줘\\n싹쓰리 (유두래곤, 린다G, 비룡)', '거짓말이라도 해서 널 보고싶어\\n백지영', '보라빛 밤 (pporappippam)\\n선미', '모든 날, 모든 순간 (Every day, Every Moment)\\n폴킴', \"Don't Start Now\\nDua Lipa\", '2002\\nAnne-Marie', '오늘도 빛나는 너에게 (To You My Light) (Feat.이라온)\\n마크툽 (MAKTUB)', '처음처럼\\n엠씨더맥스 (M.C the MAX)', '아무노래\\n지코 (ZICO)', '마음을 드려요\\n아이유', '봄날\\n방탄소년단', 'ON\\n방탄소년단', '우리 왜 헤어져야 해\\n신예영', '시작\\n가호 (Gaho)', 'Into the I-LAND\\n아이유', '신난다 (Feat. 마마무)\\n비룡', '안녕\\n폴킴', '여름 안에서 by 싹쓰리 (Feat. 황광희)\\n싹쓰리 (유두래곤, 린다G, 비룡)', 'Tight\\n10CM', 'Maniac\\nConan Gray']\n"
     ]
    }
   ],
   "source": [
    " # chrome driver 설정\n",
    "driver = webdriver.Chrome(DRIVER_PATH)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "url = \"https://www.melon.com/chart/index.htm\"\n",
    "\n",
    "driver.get(url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 빈 리스트 변수\n",
    "title_list = []\n",
    "\n",
    "# title crawling (TOP 50)\n",
    "for i in range(1, 51):\n",
    "    title = WebDriverWait(driver, 20) \\\n",
    "        .until(EC.presence_of_element_located((By.XPATH, f\"//*[@id='frm']/div/table/tbody/tr[{i}]/td[4]/div/div\")))\n",
    "    title_list.append(title.text)\n",
    "    \n",
    "print(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3. Text Crawling (Click & Back)\n",
    "\n",
    "# chrome driver 설정\n",
    "driver = webdriver.Chrome(DRIVER_PATH)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "url = \"https://www.melon.com/chart/index.htm\"\n",
    "\n",
    "driver.get(url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 1번째 click하기\n",
    "click_element = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"frm\"]/div/table/tbody/tr[1]/td[3]/div/a')))\n",
    "click_element.click()    \n",
    "\n",
    "# back\n",
    "driver.back()\n",
    "\n",
    "\n",
    "# 2번째 click하기\n",
    "click_element = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"frm\"]/div/table/tbody/tr[2]/td[3]/div/a')))\n",
    "click_element.click()    \n",
    "\n",
    "# back\n",
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['방탄소년단']\n",
      "['방탄소년단']\n",
      "['275,161']\n",
      "[\"Cos ah ah\\nI’m in the stars tonight\\nSo watch me bring the fire\\nand set the night alight\\nShoes on get up in the morn\\nCup of milk let’s rock and roll\\nKing Kong kick the drum\\nrolling on like a rolling stone\\nSing song when I’m walking home\\nJump up to the top LeBron\\nDing dong call me on my phone\\nIce tea and a game of ping pong\\nThis is getting heavy\\nCan you hear the bass boom\\nI’m ready\\nLife is sweet as honey\\nYeah this beat cha ching\\nlike money\\nDisco overload I’m into\\nthat I’m good to go\\nI'm diamond you know I glow up\\nHey so let’s go\\nCos ah ah\\nI’m in the stars tonight\\nSo watch me bring the fire\\nand set the night alight\\nShining through the city\\nwith a little funk and soul\\nSo I’mma light it up\\nlike dynamite woah\\nBring a friend join the crowd\\nWhoever wanna come along\\nWord up talk the talk\\njust move like we off the wall\\nDay or night the sky’s alight\\nSo we dance to the break of dawn\\nLadies and gentlemen\\nI got the medicine\\nso you should keep ya\\neyes on the ball huh\\nThis is getting heavy\\nCan you hear the bass boom\\nI’m ready\\nLife is sweet as honey\\nYeah this beat cha ching\\nlike money\\nDisco overload\\nI’m into that I’m good to go\\nI'm diamond you know I glow up\\nLet’s go\\nCos ah ah\\nI’m in the stars tonight\\nSo watch me bring the fire\\nand set the night alight\\nShining through the city\\nwith a little funk and soul\\nSo I’mma light it up\\nlike dynamite woah\\nDynnnnnanana life is dynamite\\nDynnnnnanana life is dynamite\\nShining through the city\\nwith a little funk and soul\\nSo I’mma light it up\\nlike dynamite woah\\nDynnnnnanana eh\\nDynnnnnanana eh\\nDynnnnnanana eh\\nLight it up like dynamite\\nDynnnnnanana eh\\nDynnnnnanana eh\\nDynnnnnanana eh\\nLight it up like dynamite\\nCos ah ah\\nI’m in the stars tonight\\nSo watch me bring the fire\\nand set the night alight\\nShining through the city\\nwith a little funk and soul\\nSo I’mma light it up\\nlike dynamite\\nCos ah ah\\nI’m in the stars tonight\\nSo watch me bring the fire\\nand set the night alight\\nShining through the city\\nwith a little funk and soul\\nSo I’mma light it up\\nlike dynamite woah\\nDynnnnnanana life is dynamite\\nDynnnnnanana life is dynamite\\nShining through the city\\nwith a little funk and soul\\nSo I’mma light it up\\nlike dynamite woah\"]\n"
     ]
    }
   ],
   "source": [
    "# chrome driver 설정\n",
    "driver = webdriver.Chrome(DRIVER_PATH)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "url = \"https://www.melon.com/chart/index.htm\"\n",
    "driver.get(url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 빈 리스트 변수\n",
    "title_list = []\n",
    "artist_list = []\n",
    "heart_list = []\n",
    "lyrics_list = []\n",
    "\n",
    "# crawling (TOP 5)\n",
    "for i in range(1, 2):\n",
    "    # click\n",
    "    click_element = WebDriverWait(driver, 20) \\\n",
    "        .until(EC.presence_of_element_located((By.XPATH, f'//*[@id=\"frm\"]/div/table/tbody/tr[{i}]/td[3]/div/a')))\n",
    "    click_element.click()\n",
    "\n",
    "    # title crawling\n",
    "    title = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#downloadfrm > div > div > div.entry > div.info > div.song_name\")))\n",
    "    title_list.append(title.text)\n",
    "\n",
    "    # artist crawling\n",
    "    artist = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#downloadfrm > div > div > div.entry > div.info > div.artist > a > span:nth-child(1)\")))\n",
    "    artist_list.append(artist.text)\n",
    "    \n",
    "    # heart crawling\n",
    "    heart = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#d_like_count\")))\n",
    "    heart_list.append(heart.text)\n",
    "\n",
    "    # lyrics crawling\n",
    "    lyrics = WebDriverWait(driver, 20).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"#d_video_summary\")))\n",
    "    lyrics_list.append(lyrics.text)\n",
    "    \n",
    "    # back\n",
    "    driver.back()\n",
    "    \n",
    "print(title_list)\n",
    "print(artist_list)\n",
    "print(heart_list)\n",
    "print(lyrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 변수\n",
    "raw_result = {'title': title_list,\n",
    "              'artist': artist_list,\n",
    "              'heart': heart_list,\n",
    "          'lyrics': lyrics_list}\n",
    "\n",
    "result = pd.DataFrame(raw_result)\n",
    "\n",
    "# # csv 파일로 save\n",
    "# result.to_csv(\"MelonTop5\", mode='w')\n",
    "\n",
    "# driver 종료\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>heart</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dynamite</td>\n",
       "      <td>방탄소년단</td>\n",
       "      <td>275,155</td>\n",
       "      <td>Cos ah ah\\nI’m in the stars tonight\\nSo watch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>취기를 빌려 (취향저격 그녀 X 산들)</td>\n",
       "      <td>산들</td>\n",
       "      <td>100,872</td>\n",
       "      <td>언제부턴가 불쑥\\n내 습관이 돼버린 너\\n혹시나 이런 맘이\\n어쩌면 부담일까\\n널 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>눈누난나 (NUNU NANA)</td>\n",
       "      <td>제시 (Jessi)</td>\n",
       "      <td>75,506</td>\n",
       "      <td>I’m trying to give u\\nsomething more\\nSo come ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>마리아 (Maria)</td>\n",
       "      <td>화사 (Hwa Sa)</td>\n",
       "      <td>139,402</td>\n",
       "      <td>욕을 하도 먹어 체했어 하도\\n서러워도 어쩌겠어 I do\\n모두들 미워하느라 애썼네...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>다시 여기 바닷가</td>\n",
       "      <td>싹쓰리 (유두래곤, 린다G, 비룡)</td>\n",
       "      <td>221,989</td>\n",
       "      <td>예아 호우 예예예\\n싹쓰리 인더 하우스\\n커커커커커몬 싹 쓰리 투 렛츠고\\n나 다시...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title               artist    heart  \\\n",
       "0               Dynamite                방탄소년단  275,155   \n",
       "1  취기를 빌려 (취향저격 그녀 X 산들)                   산들  100,872   \n",
       "2       눈누난나 (NUNU NANA)           제시 (Jessi)   75,506   \n",
       "3            마리아 (Maria)          화사 (Hwa Sa)  139,402   \n",
       "4              다시 여기 바닷가  싹쓰리 (유두래곤, 린다G, 비룡)  221,989   \n",
       "\n",
       "                                              lyrics  \n",
       "0  Cos ah ah\\nI’m in the stars tonight\\nSo watch ...  \n",
       "1  언제부턴가 불쑥\\n내 습관이 돼버린 너\\n혹시나 이런 맘이\\n어쩌면 부담일까\\n널 ...  \n",
       "2  I’m trying to give u\\nsomething more\\nSo come ...  \n",
       "3  욕을 하도 먹어 체했어 하도\\n서러워도 어쩌겠어 I do\\n모두들 미워하느라 애썼네...  \n",
       "4  예아 호우 예예예\\n싹쓰리 인더 하우스\\n커커커커커몬 싹 쓰리 투 렛츠고\\n나 다시...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://cdnimg.melon.co.kr/cm2/album/images/104/79/150/10479150_20200918102847_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/63/600/10463600_20200720152905_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/69/416/10469416_20200730151034_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/52/351/10452351_20200629152036_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/62/799/10462799_20200717150822_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/75/061/10475061_20200812120927_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm/album/images/021/48/596/2148596_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/51/566/10451566_20200626114914_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/26/648/10426648_20200506153340_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/78/925/10478925_20200820171048_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/23/289/10423289_20200427153909_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/09/054/10409054_20200326163459_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm/album/images/101/17/789/10117789_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/99/190/10399190_20200305151138_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/65/994/10465994_20200723160043_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/46/650/10346650_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/53/701/10453701_20200701151802_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/16/394/10316394_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/70/992/10470992_20200803154248_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/20/500/10320500_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/30/593/10330593_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/23/289/10423289_20200427153909_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/59/162/10359162_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/76/630/10476630_20200818114209_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/31/947/10331947_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm/album/images/102/73/641/10273641_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/40/381/10440381_20200605161232_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/48/811/10348811_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/33/754/10433754_20200521162928_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/82/568/10482568_20200828104231_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/60/544/10460544_20200714151651_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm/album/images/101/49/492/10149492_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/67/129/10467129_20200724181802_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/52/354/10452354_20200629152048_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/45/880/10345880_20200326181909_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm/album/images/101/37/250/10137250_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm/album/images/102/94/603/10294603_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/08/131/10408131_20200325151939_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/75/118/10375118_20200113150502_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/88/744/10388744_20200214175740_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/53/881/10353881_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm/album/images/100/37/969/10037969_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/77/346/10377346_20200221153622_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/81/712/10381712_20200131110358_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/47/670/10447670_20200619160619_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/17/137/10317137_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/103/43/276/10343276_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/05/712/10405712_20200320102711_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/59/197/10459197_20200720141408_500.jpg/melon/resize/120/quality/80/optimize', 'https://cdnimg.melon.co.kr/cm2/album/images/104/70/448/10470448_20200731163952_500.jpg/melon/resize/120/quality/80/optimize']\n"
     ]
    }
   ],
   "source": [
    " # chrome driver 설정\n",
    "driver = webdriver.Chrome(DRIVER_PATH)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "url = \"https://www.melon.com/chart/index.htm\"\n",
    "\n",
    "driver.get(url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 빈 리스트 변수\n",
    "link_list = []\n",
    "\n",
    "# # img crawling (TOP 50)\n",
    "for i in range(1, 51):\n",
    "    \n",
    "    img = WebDriverWait(driver, 20) \\\n",
    "        .until(EC.presence_of_element_located((By.CSS_SELECTOR, f\"#frm > div > table > tbody > tr:nth-child({i}) > td:nth-child(2) > div > a > img\")))\n",
    "\n",
    "    link_list.append(img.get_attribute('src'))\n",
    "\n",
    "print(link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "count = 0\n",
    "for link in link_list:\n",
    "    count += 1\n",
    "    urllib.request.urlretrieve(link, 'C:\\\\Users\\\\Administrator\\\\Desktop\\\\비즈니스_애널리틱스\\\\개인과제\\\\3주차_개인과제\\\\img/img' + str(count) + '.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C:\\Users\\Administrator\\Desktop\\비즈니스_애널리틱스\\개인과제\\3주차_개인과제\\img 폴더에 위에서 구한 사진들을 다운받아졌습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹 크롤링1 - Static Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. urllib.request를 이용한 다운로드\n",
    "    urllib.request 모듈에 있는 urlretrieve() 함수 이용\n",
    "    다음의 코드는 PNG 파일을 test.png 라는 이름의 파일로 저장하는 예제임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장되었습니다\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 읽어들이기 \n",
    "from urllib import request\n",
    "\n",
    "url=\"http://uta.pw/shodou/img/28/214.png\" # 이 주소에 있는 사진을 test.png로 저장\n",
    "savename=\"test.png\"\n",
    "\n",
    "request.urlretrieve(url, savename)\n",
    "print(\"저장되었습니다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. urlopen으로 파일에 저장하는 방법\n",
    "    request.urlopen()은 메모리에 데이터를 올린 후 파일에 저장하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장되었습니다..\n"
     ]
    }
   ],
   "source": [
    "# URL과 저장경로 지정하기\n",
    "url = \"http://uta.pw/shodou/img/28/214.png\"\n",
    "savename = \"test1.png\"\n",
    "#다운로드\n",
    "mem = request.urlopen(url).read()\n",
    "#파일로 저장하기, wb는 쓰기와 바이너리모드\n",
    "with open(savename, mode=\"wb\") as f:\n",
    "    f.write(mem)\n",
    "    print(\"저장되었습니다..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. API 사용하기\n",
    "\n",
    "### 클라이언트 접속 정보 출력 (기본)\n",
    "    API는 사용자의 요청에 따라 정보를 반환하는 프로그램\n",
    "    IP 주소, UserAgent 등 클라이언트 접속정보 출력하는 \"IP 확인 API\" 접근해서 정보를 추출하는 프로그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ip]\n",
      "API_URI=http://api.aoikujira.com/ip/get.php\n",
      "REMOTE_ADDR=211.106.174.10\n",
      "REMOTE_HOST=211.106.174.10\n",
      "REMOTE_PORT=41916\n",
      "HTTP_HOST=api.aoikujira.com\n",
      "HTTP_USER_AGENT=Python-urllib/3.7\n",
      "HTTP_ACCEPT_LANGUAGE=\n",
      "HTTP_ACCEPT_CHARSET=\n",
      "SERVER_PORT=80\n",
      "FORMAT=ini\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#데이터 읽어들이기\n",
    "url=\"http://api.aoikujira.com/ip/ini\"\n",
    "res=request.urlopen(url)\n",
    "data=res.read()\n",
    "\n",
    "#바이너리를 문자열로 변환하기\n",
    "text=data.decode(\"utf-8\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. BeautifulSoup\n",
    "    1.스크레이핑(Scraping or Crawling)이란 웹 사이트에서 데이터를 추출하고, 원하는 정보를 추출하는 것을 의미\n",
    "    2.BeautifulSoup란 파이썬으로 스크레이핑할 때 사용되는 라이브러리로서 HTML/XML에서 정보를 추출할 수 있도록 도와줌. 그러나 다운로드 기능은 없음.\n",
    "    3.파이썬 라이브러리는 pip 명령어를 이용해 설치 가능. Python Package Index(PyPI)에 있는 패키지 명령어를 한줄로 설치 가능\n",
    "        URL (http://pypi.python.org/pypi)\n",
    "    4.pip install beautifulsoup4\n",
    "    예제 HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패키지 import 및 예제 HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <h1>스크레이핑이란?</h1>\n",
    "  <p>웹 페이지를 분석하는 것</p>\n",
    "  <p>원하는 부분을 추출하는 것</p>\n",
    "</body></html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. 기본 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = 스크레이핑이란?\n",
      "p  = 웹 페이지를 분석하는 것\n",
      "p  = 원하는 부분을 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "print(f\"h1 = {h1.string}\")\n",
    "print(f\"p  = {p1.string}\")\n",
    "print(f\"p  = {p2.string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. 요소를 찾는 method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>스크레이핑이란?</h1>\n"
     ]
    }
   ],
   "source": [
    "title = soup.find(\"h1\")\n",
    "body  = soup.find(\"p\")\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#title = 스크레이핑이란?\n",
      "#body = 웹 페이지를 분석하는 것\n"
     ]
    }
   ],
   "source": [
    "print(f\"#title = {title.string}\" )\n",
    "print(f\"#body = {body.string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <ul>\n",
    "    <li><a href=\"http://www.naver.com\">naver</a></li>\n",
    "    <li><a href=\"http://www.daum.net\">daum</a></li>\n",
    "  </ul>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"http://www.naver.com\">naver</a>, <a href=\"http://www.daum.net\">daum</a>] 2\n"
     ]
    }
   ],
   "source": [
    "links = soup.find_all(\"a\")\n",
    "print(links, len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver > http://www.naver.com\n",
      "daum > http://www.daum.net\n"
     ]
    }
   ],
   "source": [
    "for a in links:\n",
    "    href = a.attrs['href'] # href의 속성에 있는 속성값을 추출\n",
    "    text = a.string \n",
    "    print(text, \">\", href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Css Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "<div id=\"meigen\">\n",
    "  <h1>위키북스 도서</h1>\n",
    "  <ul class=\"items\">\n",
    "    <li>유니티 게임 이펙트 입문</li>\n",
    "    <li>스위프트로 시작하는 아이폰 앱 개발 교과서</li>\n",
    "    <li>모던 웹사이트 디자인의 정석</li>\n",
    "  </ul>\n",
    "</div>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTML 분석하기 \n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = 위키북스 도서\n",
      "li = 유니티 게임 이펙트 입문\n",
      "li = 스위프트로 시작하는 아이폰 앱 개발 교과서\n",
      "li = 모던 웹사이트 디자인의 정석\n"
     ]
    }
   ],
   "source": [
    "# 타이틀 부분 추출하기 --- (※3)\n",
    "h1 = soup.select_one(\"div#meigen > h1\").string\n",
    "print(f\"h1 = {h1}\")\n",
    "\n",
    "# 목록 부분 추출하기 --- (※4)\n",
    "li_list = soup.select(\"div#meigen > ul.items > li\")\n",
    "for li in li_list:\n",
    "  print(f\"li = {li.string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 활용 예제\n",
    "\n",
    "앞서 배운 urllib과 BeautifulSoup를 조합하면, 웹스크레이핑 및 API 요청 작업을 쉽게 수행하실 수 있습니다.\n",
    "\n",
    "URL을 이용하여 웹으로부터 html을 읽어들임 (urllib)\n",
    "html 분석 및 원하는 데이터를 추출 (BeautifulSoup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib import request, parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. 네이버 금융 - 환율 정보\n",
    "    * 다양한 금융 정보가 공개돼 있는 \"네이버 금융\"에서 원/달러 환율 정보를 추출해보자!\n",
    "    * 네이버 금융의 시장 지표 페이지 https://finance.naver.com/marketindex/\n",
    "    * 다음은 원/달러 환율 정보를 추출하는 프로그램임\n",
    "#### 1) HTML 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "res = request.urlopen(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) HTML 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 원하는 데이터 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usd/krw = 1,175.00\n"
     ]
    }
   ],
   "source": [
    "price = soup.select_one(\"div.head_info > span.value\").string\n",
    "print(\"usd/krw =\", price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. 기상청 RSS\n",
    "    *기상청 RSS에서 특정 내용을 추출하는 예제\n",
    "    *기상청 RSS에서 XML 데이터를 추출하고 XML 내용을 출력\n",
    "    *기상청의 RSS 서비스에 지역 번호를 지정하여 데이터 요청해보기                            http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp \n",
    "        *참고: 기상청 RSS http://www.kma.go.kr/weather/lifenindustry/service_rss.jsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전국\t108\t전라북도\t146\n",
    "서울/경기도\t109\t전라남도\t156\n",
    "강원도\t105\t경상북도\t143\n",
    "충청북도\t131\t경상남도\t159\n",
    "충청남도\t133\t제주특별자치도\t184"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) HTML 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url= http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=109\n"
     ]
    }
   ],
   "source": [
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "\n",
    "#매개변수를 URL로 인코딩한다.\n",
    "values = {\n",
    "    'stnId':'109'\n",
    "}\n",
    "\n",
    "params=parse.urlencode(values)\n",
    "url += \"?\"+params # URL에 매개변수 추가\n",
    "print(\"url=\", url)\n",
    "\n",
    "res = request.urlopen(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) HTML 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 원하는 데이터 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울,경기도 육상중기예보\n",
      "○ (강수) 10월 2일(금)에는 비가 내리겠습니다.<br />○ (기온) 이번 예보기간 낮 기온은 19~25도로 오늘(27일, 24~27도)보다 낮겠고, 아침 기온은 6~17도로 선선하겠습니다.<br />          특히, 내륙을 중심으로 낮과 밤의 기온차가 10도 내외로 크겠습니다.<br />○ (해상) 서해중부해상의 물결은 0.5~2.0m로 일겠습니다.\n"
     ]
    }
   ],
   "source": [
    "header = soup.find(\"header\")\n",
    "\n",
    "title = header.find(\"title\").text\n",
    "wf = header.find(\"wf\").text\n",
    "\n",
    "print(title)\n",
    "print(wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "css selector 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울,경기도 육상중기예보\n",
      "○ (강수) 10월 2일(금)에는 비가 내리겠습니다.<br />○ (기온) 이번 예보기간 낮 기온은 19~25도로 오늘(27일, 24~27도)보다 낮겠고, 아침 기온은 6~17도로 선선하겠습니다.<br />          특히, 내륙을 중심으로 낮과 밤의 기온차가 10도 내외로 크겠습니다.<br />○ (해상) 서해중부해상의 물결은 0.5~2.0m로 일겠습니다.\n"
     ]
    }
   ],
   "source": [
    "title = soup.select_one(\"header > title\").text\n",
    "wf = header.select_one(\"header wf\").text\n",
    "\n",
    "print(title)\n",
    "print(wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3. 윤동주 작가의 작품 목록    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 하늘과 바람과 별과 시\n",
      "- 증보판\n",
      "- 서시\n",
      "- 자화상\n",
      "- 소년\n",
      "- 눈 오는 지도\n",
      "- 돌아와 보는 밤\n",
      "- 병원\n",
      "- 새로운 길\n",
      "- 간판 없는 거리\n",
      "- 태초의 아침\n",
      "- 또 태초의 아침\n",
      "- 새벽이 올 때까지\n",
      "- 무서운 시간\n",
      "- 십자가\n",
      "- 바람이 불어\n",
      "- 슬픈 족속\n",
      "- 눈감고 간다\n",
      "- 또 다른 고향\n",
      "- 길\n",
      "- 별 헤는 밤\n",
      "- 흰 그림자\n",
      "- 사랑스런 추억\n",
      "- 흐르는 거리\n",
      "- 쉽게 씌어진 시\n",
      "- 봄\n",
      "- 참회록\n",
      "- 간(肝)\n",
      "- 위로\n",
      "- 팔복\n",
      "- 못자는밤\n",
      "- 달같이\n",
      "- 고추밭\n",
      "- 아우의 인상화\n",
      "- 사랑의 전당\n",
      "- 이적\n",
      "- 비오는 밤\n",
      "- 산골물\n",
      "- 유언\n",
      "- 창\n",
      "- 바다\n",
      "- 비로봉\n",
      "- 산협의 오후\n",
      "- 명상\n",
      "- 소낙비\n",
      "- 한난계\n",
      "- 풍경\n",
      "- 달밤\n",
      "- 장\n",
      "- 밤\n",
      "- 황혼이 바다가 되어\n",
      "- 아침\n",
      "- 빨래\n",
      "- 꿈은 깨어지고\n",
      "- 산림\n",
      "- 이런날\n",
      "- 산상\n",
      "- 양지쪽\n",
      "- 닭\n",
      "- 가슴 1\n",
      "- 가슴 2\n",
      "- 비둘기\n",
      "- 황혼\n",
      "- 남쪽 하늘\n",
      "- 창공\n",
      "- 거리에서\n",
      "- 삶과 죽음\n",
      "- 초한대\n",
      "- 산울림\n",
      "- 해바라기 얼굴\n",
      "- 귀뚜라미와 나와\n",
      "- 애기의 새벽\n",
      "- 햇빛·바람\n",
      "- 반디불\n",
      "- 둘 다\n",
      "- 거짓부리\n",
      "- 눈\n",
      "- 참새\n",
      "- 버선본\n",
      "- 편지\n",
      "- 봄\n",
      "- 무얼 먹구 사나\n",
      "- 굴뚝\n",
      "- 햇비\n",
      "- 빗자루\n",
      "- 기왓장 내외\n",
      "- 오줌싸개 지도\n",
      "- 병아리\n",
      "- 조개껍질\n",
      "- 겨울\n",
      "- 트루게네프의 언덕\n",
      "- 달을 쏘다\n",
      "- 별똥 떨어진 데\n",
      "- 화원에 꽃이 핀다\n",
      "- 종시\n"
     ]
    }
   ],
   "source": [
    "# 뒤의 인코딩 부분은 \"저자:윤동주\"라는 의미입니다.\n",
    "# 따로 입력하지 말고 위키 문헌 홈페이지에 들어간 뒤에 주소를 복사해서 사용하세요.\n",
    "\n",
    "url = \"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC\"\n",
    "res = request.urlopen(url)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# #mw-content-text 바로 아래에 있는 \n",
    "# ul 태그 바로 아래에 있는\n",
    "# li 태그 아래에 있는\n",
    "# a 태그를 모두 선택합니다.\n",
    "a_list = soup.select(\"#mw-content-text   ul > li  a\")\n",
    "for a in a_list:\n",
    "    name = a.string\n",
    "    print(f\"- {name}\", )  ## 제목 옆에 \"-\"을 붙일때 쓰입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일반문제\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib import request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 네이버 뉴스 헤드라인\n",
    "배운 내용을 바탕으로 네이버 뉴스(https://news.naver.com/)에서 헤드라인 뉴스의 제목을 추출해보고자 합니다.\n",
    "\n",
    "Q: 다음의 코드에 css selector를 추가하여 최신 기사의 헤드라인을 스크레이핑하는 코드를 완성하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 500: Internal Server Error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-0f5128b780fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://news.naver.com/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtitle_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 641\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 500: Internal Server Error"
     ]
    }
   ],
   "source": [
    "url = \"https://news.naver.com/\"\n",
    "\n",
    "res = request.urlopen(url)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "title_list = []\n",
    "\n",
    "selector = \"#today_main_news > div.hdline_news > ul > li > div.hdline_article_tit > a\".string\n",
    "\n",
    "for a in soup.select(selector):\n",
    "    title = a.text\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 시민의 소리 게시판\n",
    "다음은 서울시 대공원의 시민의 소리 게시판 입니다.\n",
    "\n",
    "https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgList.do?pgno=1\n",
    "\n",
    "해당 페이지에 나타난 게시글들의 제목을 수집하고자 합니다.\n",
    "\n",
    "Q: 다음의 코드에 css selector를 추가하여 해당 페이지에서 게시글의 제목을 스크레이핑하는 코드를 완성하시오. 또한 과제 제출시 하단의 추가 내용을 참고하여 수집한 데이터를 csv 형태로 저장하여 해당 csv 파일도 함께 제출하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['관리인 마스크', '어린이 대공원 쓰레기집하장 내 쓰레기 제거 요청 ', '마스크미착용으로 축구 및, 베트민턴 치는 인원이 너무 많아요.', '공원 내 마스크 착용', '청춘핫도그 점장님과 직원분께 감사드립니다', '카드결제를 거부하는 매점을 신고합니다', '참얼굴만큼예쁘고맘씨좋은 여직원을 만나 고마워서 글을남깁니다.', '놀이동산에서 불쾌함을 겪었습니다', '서문 플래카드', '간만에 친절한 아가씨를 만났어요.(놀이동산)'] ['https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=lDa1hGEdWvfPwk6dAamxYxMK4JwXB5aUoIQvTEHfjNLiGAHSVlU72kyqMgHduHHe.etisw2_servlet_user?qnaid=QNAS20200917000010&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=lDa1hGEdWvfPwk6dAamxYxMK4JwXB5aUoIQvTEHfjNLiGAHSVlU72kyqMgHduHHe.etisw2_servlet_user?qnaid=QNAS20200902000003&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=lDa1hGEdWvfPwk6dAamxYxMK4JwXB5aUoIQvTEHfjNLiGAHSVlU72kyqMgHduHHe.etisw2_servlet_user?qnaid=QNAS20200826000002&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=lDa1hGEdWvfPwk6dAamxYxMK4JwXB5aUoIQvTEHfjNLiGAHSVlU72kyqMgHduHHe.etisw2_servlet_user?qnaid=QNAS20200825000003&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=lDa1hGEdWvfPwk6dAamxYxMK4JwXB5aUoIQvTEHfjNLiGAHSVlU72kyqMgHduHHe.etisw2_servlet_user?qnaid=QNAS20200818000009&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=lDa1hGEdWvfPwk6dAamxYxMK4JwXB5aUoIQvTEHfjNLiGAHSVlU72kyqMgHduHHe.etisw2_servlet_user?qnaid=QNAS20200816000002&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=lDa1hGEdWvfPwk6dAamxYxMK4JwXB5aUoIQvTEHfjNLiGAHSVlU72kyqMgHduHHe.etisw2_servlet_user?qnaid=QNAS20200813000003&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=lDa1hGEdWvfPwk6dAamxYxMK4JwXB5aUoIQvTEHfjNLiGAHSVlU72kyqMgHduHHe.etisw2_servlet_user?qnaid=QNAS20200813000002&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=lDa1hGEdWvfPwk6dAamxYxMK4JwXB5aUoIQvTEHfjNLiGAHSVlU72kyqMgHduHHe.etisw2_servlet_user?qnaid=QNAS20200730000004&pgno=1', 'https://www.sisul.or.kr/open_content/childrenpark/qna/qnaMsgDetail.do;jsessionid=lDa1hGEdWvfPwk6dAamxYxMK4JwXB5aUoIQvTEHfjNLiGAHSVlU72kyqMgHduHHe.etisw2_servlet_user?qnaid=QNAS20200728000002&pgno=1']\n"
     ]
    }
   ],
   "source": [
    "url_head = \"https://www.sisul.or.kr\"\n",
    "\n",
    "url_board = url_head + \"/open_content/childrenpark/qna/qnaMsgList.do?pgno=1\"\n",
    "\n",
    "\n",
    "\n",
    "res = request.urlopen(url_board)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# selector = \"#detail_con > div.generalboard > table > tbody > tr > td.left.title > a\"\n",
    "selector = \"#detail_con > div.generalboard > table > tbody > tr > td.left.title > a\"\n",
    "titles = []\n",
    "links = []\n",
    "for a in soup.select(selector):\n",
    "    titles.append(a.text)\n",
    "    links.append(url_head + a.attrs[\"href\"])\n",
    "    \n",
    "print(titles, links)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가 내용\n",
    "수집된 자료를 데이터프레임으로 만들어 csv로 저장하는 것이 일반적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>관리인 마스크</td>\n",
       "      <td>https://www.sisul.or.kr/open_content/childrenp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>어린이 대공원 쓰레기집하장 내 쓰레기 제거 요청</td>\n",
       "      <td>https://www.sisul.or.kr/open_content/childrenp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>마스크미착용으로 축구 및, 베트민턴 치는 인원이 너무 많아요.</td>\n",
       "      <td>https://www.sisul.or.kr/open_content/childrenp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>공원 내 마스크 착용</td>\n",
       "      <td>https://www.sisul.or.kr/open_content/childrenp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>청춘핫도그 점장님과 직원분께 감사드립니다</td>\n",
       "      <td>https://www.sisul.or.kr/open_content/childrenp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0                             관리인 마스크   \n",
       "1         어린이 대공원 쓰레기집하장 내 쓰레기 제거 요청    \n",
       "2  마스크미착용으로 축구 및, 베트민턴 치는 인원이 너무 많아요.   \n",
       "3                         공원 내 마스크 착용   \n",
       "4              청춘핫도그 점장님과 직원분께 감사드립니다   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.sisul.or.kr/open_content/childrenp...  \n",
       "1  https://www.sisul.or.kr/open_content/childrenp...  \n",
       "2  https://www.sisul.or.kr/open_content/childrenp...  \n",
       "3  https://www.sisul.or.kr/open_content/childrenp...  \n",
       "4  https://www.sisul.or.kr/open_content/childrenp...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "board_df = pd.DataFrame({\"title\": titles, \"link\": links})\n",
    "board_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_df.to_csv(\"board.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
